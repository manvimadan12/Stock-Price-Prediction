{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the training set\n",
    "dataset_train = pd.read_csv('Google_Stock_Price_Train.csv')\n",
    "training_set = dataset_train.iloc[:, 1:2].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/3/2012</td>\n",
       "      <td>325.25</td>\n",
       "      <td>332.83</td>\n",
       "      <td>324.97</td>\n",
       "      <td>663.59</td>\n",
       "      <td>7,380,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/4/2012</td>\n",
       "      <td>331.27</td>\n",
       "      <td>333.87</td>\n",
       "      <td>329.08</td>\n",
       "      <td>666.45</td>\n",
       "      <td>5,749,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/5/2012</td>\n",
       "      <td>329.83</td>\n",
       "      <td>330.75</td>\n",
       "      <td>326.89</td>\n",
       "      <td>657.21</td>\n",
       "      <td>6,590,300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/6/2012</td>\n",
       "      <td>328.34</td>\n",
       "      <td>328.77</td>\n",
       "      <td>323.68</td>\n",
       "      <td>648.24</td>\n",
       "      <td>5,405,900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/9/2012</td>\n",
       "      <td>322.04</td>\n",
       "      <td>322.29</td>\n",
       "      <td>309.46</td>\n",
       "      <td>620.76</td>\n",
       "      <td>11,688,800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>12/23/2016</td>\n",
       "      <td>790.90</td>\n",
       "      <td>792.74</td>\n",
       "      <td>787.28</td>\n",
       "      <td>789.91</td>\n",
       "      <td>623,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>12/27/2016</td>\n",
       "      <td>790.68</td>\n",
       "      <td>797.86</td>\n",
       "      <td>787.66</td>\n",
       "      <td>791.55</td>\n",
       "      <td>789,100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>12/28/2016</td>\n",
       "      <td>793.70</td>\n",
       "      <td>794.23</td>\n",
       "      <td>783.20</td>\n",
       "      <td>785.05</td>\n",
       "      <td>1,153,800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>12/29/2016</td>\n",
       "      <td>783.33</td>\n",
       "      <td>785.93</td>\n",
       "      <td>778.92</td>\n",
       "      <td>782.79</td>\n",
       "      <td>744,300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>12/30/2016</td>\n",
       "      <td>782.75</td>\n",
       "      <td>782.78</td>\n",
       "      <td>770.41</td>\n",
       "      <td>771.82</td>\n",
       "      <td>1,770,000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1258 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date    Open    High     Low   Close      Volume\n",
       "0       1/3/2012  325.25  332.83  324.97  663.59   7,380,500\n",
       "1       1/4/2012  331.27  333.87  329.08  666.45   5,749,400\n",
       "2       1/5/2012  329.83  330.75  326.89  657.21   6,590,300\n",
       "3       1/6/2012  328.34  328.77  323.68  648.24   5,405,900\n",
       "4       1/9/2012  322.04  322.29  309.46  620.76  11,688,800\n",
       "...          ...     ...     ...     ...     ...         ...\n",
       "1253  12/23/2016  790.90  792.74  787.28  789.91     623,400\n",
       "1254  12/27/2016  790.68  797.86  787.66  791.55     789,100\n",
       "1255  12/28/2016  793.70  794.23  783.20  785.05   1,153,800\n",
       "1256  12/29/2016  783.33  785.93  778.92  782.79     744,300\n",
       "1257  12/30/2016  782.75  782.78  770.41  771.82   1,770,000\n",
       "\n",
       "[1258 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "training_set_scaled = sc.fit_transform(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a data structure with 60 timesteps and 1 output\n",
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(60, 1258):\n",
    "    X_train.append(training_set_scaled[i-60:i, 0])\n",
    "    y_train.append(training_set_scaled[i, 0])\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the RNN\n",
    "regressor = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the first LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = False, input_shape = (X_train.shape[1], 1)))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer lstm_4: expected ndim=3, found ndim=2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-c3e15d882a0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Adding a second LSTM layer and some Dropout regularisation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_source_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    444\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                                      str(K.ndim(x)))\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer lstm_4: expected ndim=3, found ndim=2"
     ]
    }
   ],
   "source": [
    "# Adding a second LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = False))\n",
    "regressor.add(Dropout(0.2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer lstm_5: expected ndim=3, found ndim=2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-23e3704ce11f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Adding a third LSTM layer and some Dropout regularisation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_source_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    444\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                                      str(K.ndim(x)))\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer lstm_5: expected ndim=3, found ndim=2"
     ]
    }
   ],
   "source": [
    "# Adding a third LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = False))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer lstm_6: expected ndim=3, found ndim=2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-3d16ffef3407>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Adding a fourth LSTM layer and some Dropout regularisation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_source_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    444\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                                      str(K.ndim(x)))\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer lstm_6: expected ndim=3, found ndim=2"
     ]
    }
   ],
   "source": [
    "# Adding a fourth LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50))\n",
    "regressor.add(Dropout(0.2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the output layer\n",
    "regressor.add(Dense(units = 1, activation = 'linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the RNN\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 958 samples, validate on 240 samples\n",
      "Epoch 1/100\n",
      "958/958 [==============================] - 1s 819us/step - loss: 0.0431 - accuracy: 0.0010 - val_loss: 0.0369 - val_accuracy: 0.0042\n",
      "Epoch 2/100\n",
      "958/958 [==============================] - 1s 535us/step - loss: 0.0055 - accuracy: 0.0010 - val_loss: 0.0012 - val_accuracy: 0.0042\n",
      "Epoch 3/100\n",
      "958/958 [==============================] - 1s 533us/step - loss: 0.0038 - accuracy: 0.0010 - val_loss: 0.0025 - val_accuracy: 0.0042\n",
      "Epoch 4/100\n",
      "958/958 [==============================] - 1s 540us/step - loss: 0.0034 - accuracy: 0.0010 - val_loss: 0.0016 - val_accuracy: 0.0042\n",
      "Epoch 5/100\n",
      "958/958 [==============================] - 1s 537us/step - loss: 0.0030 - accuracy: 0.0010 - val_loss: 0.0015 - val_accuracy: 0.0042\n",
      "Epoch 6/100\n",
      "958/958 [==============================] - 1s 546us/step - loss: 0.0031 - accuracy: 0.0010 - val_loss: 0.0012 - val_accuracy: 0.0042\n",
      "Epoch 7/100\n",
      "958/958 [==============================] - 1s 555us/step - loss: 0.0028 - accuracy: 0.0010 - val_loss: 0.0013 - val_accuracy: 0.0042\n",
      "Epoch 8/100\n",
      "958/958 [==============================] - 1s 552us/step - loss: 0.0027 - accuracy: 0.0010 - val_loss: 0.0011 - val_accuracy: 0.0042\n",
      "Epoch 9/100\n",
      "958/958 [==============================] - 1s 546us/step - loss: 0.0025 - accuracy: 0.0010 - val_loss: 0.0010 - val_accuracy: 0.0042\n",
      "Epoch 10/100\n",
      "958/958 [==============================] - 1s 534us/step - loss: 0.0024 - accuracy: 0.0010 - val_loss: 9.8609e-04 - val_accuracy: 0.0042\n",
      "Epoch 11/100\n",
      "958/958 [==============================] - 1s 529us/step - loss: 0.0023 - accuracy: 0.0010 - val_loss: 0.0022 - val_accuracy: 0.0042\n",
      "Epoch 12/100\n",
      "958/958 [==============================] - 1s 546us/step - loss: 0.0021 - accuracy: 0.0010 - val_loss: 0.0030 - val_accuracy: 0.0042\n",
      "Epoch 13/100\n",
      "958/958 [==============================] - 1s 551us/step - loss: 0.0021 - accuracy: 0.0010 - val_loss: 9.5287e-04 - val_accuracy: 0.0042\n",
      "Epoch 14/100\n",
      "958/958 [==============================] - 1s 559us/step - loss: 0.0022 - accuracy: 0.0010 - val_loss: 9.3118e-04 - val_accuracy: 0.0042\n",
      "Epoch 15/100\n",
      "958/958 [==============================] - 1s 549us/step - loss: 0.0020 - accuracy: 0.0010 - val_loss: 0.0022 - val_accuracy: 0.0042\n",
      "Epoch 16/100\n",
      "958/958 [==============================] - 1s 557us/step - loss: 0.0021 - accuracy: 0.0010 - val_loss: 0.0025 - val_accuracy: 0.0042\n",
      "Epoch 17/100\n",
      "958/958 [==============================] - 1s 534us/step - loss: 0.0018 - accuracy: 0.0010 - val_loss: 0.0026 - val_accuracy: 0.0042\n",
      "Epoch 18/100\n",
      "958/958 [==============================] - 1s 540us/step - loss: 0.0019 - accuracy: 0.0010 - val_loss: 9.5732e-04 - val_accuracy: 0.0042\n",
      "Epoch 19/100\n",
      "958/958 [==============================] - 1s 536us/step - loss: 0.0017 - accuracy: 0.0010 - val_loss: 0.0019 - val_accuracy: 0.0042\n",
      "Epoch 20/100\n",
      "958/958 [==============================] - 1s 537us/step - loss: 0.0017 - accuracy: 0.0010 - val_loss: 0.0012 - val_accuracy: 0.0042\n",
      "Epoch 21/100\n",
      "958/958 [==============================] - 1s 538us/step - loss: 0.0017 - accuracy: 0.0010 - val_loss: 9.3700e-04 - val_accuracy: 0.0042\n",
      "Epoch 22/100\n",
      "958/958 [==============================] - 1s 529us/step - loss: 0.0019 - accuracy: 0.0010 - val_loss: 0.0035 - val_accuracy: 0.0042\n",
      "Epoch 23/100\n",
      "958/958 [==============================] - 1s 533us/step - loss: 0.0019 - accuracy: 0.0010 - val_loss: 0.0011 - val_accuracy: 0.0042\n",
      "Epoch 24/100\n",
      "958/958 [==============================] - 1s 531us/step - loss: 0.0015 - accuracy: 0.0010 - val_loss: 9.1933e-04 - val_accuracy: 0.0042\n",
      "Epoch 25/100\n",
      "958/958 [==============================] - 1s 550us/step - loss: 0.0016 - accuracy: 0.0010 - val_loss: 8.9026e-04 - val_accuracy: 0.0042\n",
      "Epoch 26/100\n",
      "958/958 [==============================] - 1s 547us/step - loss: 0.0016 - accuracy: 0.0010 - val_loss: 0.0010 - val_accuracy: 0.0042\n",
      "Epoch 27/100\n",
      "958/958 [==============================] - 1s 536us/step - loss: 0.0017 - accuracy: 0.0010 - val_loss: 9.5566e-04 - val_accuracy: 0.0042\n",
      "Epoch 28/100\n",
      "958/958 [==============================] - 1s 537us/step - loss: 0.0016 - accuracy: 0.0010 - val_loss: 0.0019 - val_accuracy: 0.0042\n",
      "Epoch 29/100\n",
      "958/958 [==============================] - 1s 539us/step - loss: 0.0017 - accuracy: 0.0010 - val_loss: 0.0019 - val_accuracy: 0.0042\n",
      "Epoch 30/100\n",
      "958/958 [==============================] - 1s 537us/step - loss: 0.0018 - accuracy: 0.0010 - val_loss: 0.0016 - val_accuracy: 0.0042\n",
      "Epoch 31/100\n",
      "958/958 [==============================] - 1s 535us/step - loss: 0.0016 - accuracy: 0.0010 - val_loss: 8.4787e-04 - val_accuracy: 0.0042\n",
      "Epoch 32/100\n",
      "958/958 [==============================] - 1s 537us/step - loss: 0.0015 - accuracy: 0.0010 - val_loss: 0.0013 - val_accuracy: 0.0042\n",
      "Epoch 33/100\n",
      "958/958 [==============================] - 1s 536us/step - loss: 0.0016 - accuracy: 0.0010 - val_loss: 8.3016e-04 - val_accuracy: 0.0042\n",
      "Epoch 34/100\n",
      "958/958 [==============================] - 1s 558us/step - loss: 0.0017 - accuracy: 0.0010 - val_loss: 0.0012 - val_accuracy: 0.0042\n",
      "Epoch 35/100\n",
      "958/958 [==============================] - 1s 547us/step - loss: 0.0015 - accuracy: 0.0010 - val_loss: 0.0022 - val_accuracy: 0.0042\n",
      "Epoch 36/100\n",
      "958/958 [==============================] - 1s 552us/step - loss: 0.0014 - accuracy: 0.0010 - val_loss: 8.2015e-04 - val_accuracy: 0.0042\n",
      "Epoch 37/100\n",
      "958/958 [==============================] - 1s 538us/step - loss: 0.0016 - accuracy: 0.0010 - val_loss: 8.1456e-04 - val_accuracy: 0.0042\n",
      "Epoch 38/100\n",
      "958/958 [==============================] - 1s 537us/step - loss: 0.0015 - accuracy: 0.0010 - val_loss: 8.3498e-04 - val_accuracy: 0.0042\n",
      "Epoch 39/100\n",
      "958/958 [==============================] - 1s 548us/step - loss: 0.0015 - accuracy: 0.0010 - val_loss: 0.0012 - val_accuracy: 0.0042\n",
      "Epoch 40/100\n",
      "958/958 [==============================] - 1s 546us/step - loss: 0.0014 - accuracy: 0.0010 - val_loss: 0.0011 - val_accuracy: 0.0042\n",
      "Epoch 41/100\n",
      "958/958 [==============================] - 1s 536us/step - loss: 0.0016 - accuracy: 0.0010 - val_loss: 8.1153e-04 - val_accuracy: 0.0042\n",
      "Epoch 42/100\n",
      "958/958 [==============================] - 1s 565us/step - loss: 0.0013 - accuracy: 0.0010 - val_loss: 9.5021e-04 - val_accuracy: 0.0042\n",
      "Epoch 43/100\n",
      "958/958 [==============================] - 1s 554us/step - loss: 0.0014 - accuracy: 0.0010 - val_loss: 7.6980e-04 - val_accuracy: 0.0042\n",
      "Epoch 44/100\n",
      "958/958 [==============================] - 1s 568us/step - loss: 0.0013 - accuracy: 0.0010 - val_loss: 0.0013 - val_accuracy: 0.0042\n",
      "Epoch 45/100\n",
      "958/958 [==============================] - 1s 548us/step - loss: 0.0013 - accuracy: 0.0010 - val_loss: 0.0013 - val_accuracy: 0.0042\n",
      "Epoch 46/100\n",
      "958/958 [==============================] - 1s 551us/step - loss: 0.0015 - accuracy: 0.0010 - val_loss: 7.7906e-04 - val_accuracy: 0.0042\n",
      "Epoch 47/100\n",
      "958/958 [==============================] - 1s 547us/step - loss: 0.0013 - accuracy: 0.0010 - val_loss: 0.0013 - val_accuracy: 0.0042\n",
      "Epoch 48/100\n",
      "958/958 [==============================] - 1s 556us/step - loss: 0.0013 - accuracy: 0.0010 - val_loss: 7.4287e-04 - val_accuracy: 0.0042\n",
      "Epoch 49/100\n",
      "958/958 [==============================] - 1s 546us/step - loss: 0.0013 - accuracy: 0.0010 - val_loss: 0.0010 - val_accuracy: 0.0042\n",
      "Epoch 50/100\n",
      "958/958 [==============================] - 1s 553us/step - loss: 0.0013 - accuracy: 0.0010 - val_loss: 8.1853e-04 - val_accuracy: 0.0042\n",
      "Epoch 51/100\n",
      "958/958 [==============================] - 1s 561us/step - loss: 0.0013 - accuracy: 0.0010 - val_loss: 8.4686e-04 - val_accuracy: 0.0042\n",
      "Epoch 52/100\n",
      "958/958 [==============================] - 1s 548us/step - loss: 0.0013 - accuracy: 0.0010 - val_loss: 8.0106e-04 - val_accuracy: 0.0042\n",
      "Epoch 53/100\n",
      "958/958 [==============================] - 1s 535us/step - loss: 0.0012 - accuracy: 0.0010 - val_loss: 7.5217e-04 - val_accuracy: 0.0042\n",
      "Epoch 54/100\n",
      "958/958 [==============================] - 1s 547us/step - loss: 0.0013 - accuracy: 0.0010 - val_loss: 7.2535e-04 - val_accuracy: 0.0042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "958/958 [==============================] - 1s 552us/step - loss: 0.0013 - accuracy: 0.0010 - val_loss: 6.9299e-04 - val_accuracy: 0.0042\n",
      "Epoch 56/100\n",
      "958/958 [==============================] - 1s 544us/step - loss: 0.0012 - accuracy: 0.0010 - val_loss: 7.1681e-04 - val_accuracy: 0.0042\n",
      "Epoch 57/100\n",
      "958/958 [==============================] - 1s 545us/step - loss: 0.0013 - accuracy: 0.0010 - val_loss: 0.0011 - val_accuracy: 0.0042\n",
      "Epoch 58/100\n",
      "958/958 [==============================] - 1s 543us/step - loss: 0.0012 - accuracy: 0.0010 - val_loss: 9.1751e-04 - val_accuracy: 0.0042\n",
      "Epoch 59/100\n",
      "958/958 [==============================] - 1s 539us/step - loss: 0.0012 - accuracy: 0.0010 - val_loss: 7.4635e-04 - val_accuracy: 0.0042\n",
      "Epoch 60/100\n",
      "958/958 [==============================] - 1s 545us/step - loss: 0.0012 - accuracy: 0.0010 - val_loss: 8.3102e-04 - val_accuracy: 0.0042\n",
      "Epoch 61/100\n",
      "958/958 [==============================] - 1s 549us/step - loss: 0.0012 - accuracy: 0.0010 - val_loss: 0.0012 - val_accuracy: 0.0042\n",
      "Epoch 62/100\n",
      "958/958 [==============================] - 1s 545us/step - loss: 0.0013 - accuracy: 0.0010 - val_loss: 0.0013 - val_accuracy: 0.0042\n",
      "Epoch 63/100\n",
      "958/958 [==============================] - 1s 544us/step - loss: 0.0011 - accuracy: 0.0010 - val_loss: 0.0011 - val_accuracy: 0.0042\n",
      "Epoch 64/100\n",
      "958/958 [==============================] - 1s 554us/step - loss: 0.0012 - accuracy: 0.0010 - val_loss: 0.0014 - val_accuracy: 0.0042\n",
      "Epoch 65/100\n",
      "958/958 [==============================] - 1s 544us/step - loss: 0.0010 - accuracy: 0.0010 - val_loss: 6.9715e-04 - val_accuracy: 0.0042\n",
      "Epoch 66/100\n",
      "958/958 [==============================] - 1s 541us/step - loss: 0.0011 - accuracy: 0.0010 - val_loss: 7.2167e-04 - val_accuracy: 0.0042\n",
      "Epoch 67/100\n",
      "958/958 [==============================] - 1s 537us/step - loss: 0.0011 - accuracy: 0.0010 - val_loss: 6.8438e-04 - val_accuracy: 0.0042\n",
      "Epoch 68/100\n",
      "958/958 [==============================] - 1s 548us/step - loss: 0.0011 - accuracy: 0.0010 - val_loss: 6.5255e-04 - val_accuracy: 0.0042\n",
      "Epoch 69/100\n",
      "958/958 [==============================] - 1s 538us/step - loss: 0.0011 - accuracy: 0.0010 - val_loss: 0.0013 - val_accuracy: 0.0042\n",
      "Epoch 70/100\n",
      "958/958 [==============================] - 1s 545us/step - loss: 0.0011 - accuracy: 0.0010 - val_loss: 7.0318e-04 - val_accuracy: 0.0042\n",
      "Epoch 71/100\n",
      "958/958 [==============================] - 1s 551us/step - loss: 0.0010 - accuracy: 0.0010 - val_loss: 6.1994e-04 - val_accuracy: 0.0042\n",
      "Epoch 72/100\n",
      "958/958 [==============================] - 1s 539us/step - loss: 0.0011 - accuracy: 0.0010 - val_loss: 7.2833e-04 - val_accuracy: 0.0042\n",
      "Epoch 73/100\n",
      "958/958 [==============================] - 1s 555us/step - loss: 0.0011 - accuracy: 0.0010 - val_loss: 7.2312e-04 - val_accuracy: 0.0042\n",
      "Epoch 74/100\n",
      "958/958 [==============================] - 1s 565us/step - loss: 0.0012 - accuracy: 0.0010 - val_loss: 8.3380e-04 - val_accuracy: 0.0042\n",
      "Epoch 75/100\n",
      "958/958 [==============================] - 1s 551us/step - loss: 9.7139e-04 - accuracy: 0.0010 - val_loss: 7.5404e-04 - val_accuracy: 0.0042\n",
      "Epoch 76/100\n",
      "958/958 [==============================] - 1s 537us/step - loss: 0.0010 - accuracy: 0.0010 - val_loss: 6.2772e-04 - val_accuracy: 0.0042\n",
      "Epoch 77/100\n",
      "958/958 [==============================] - 1s 528us/step - loss: 9.7508e-04 - accuracy: 0.0010 - val_loss: 6.2718e-04 - val_accuracy: 0.0042\n",
      "Epoch 78/100\n",
      "958/958 [==============================] - 1s 538us/step - loss: 8.9065e-04 - accuracy: 0.0010 - val_loss: 8.9275e-04 - val_accuracy: 0.0042\n",
      "Epoch 79/100\n",
      "958/958 [==============================] - 1s 542us/step - loss: 9.8047e-04 - accuracy: 0.0010 - val_loss: 6.2764e-04 - val_accuracy: 0.0042\n",
      "Epoch 80/100\n",
      "958/958 [==============================] - 1s 545us/step - loss: 9.6732e-04 - accuracy: 0.0010 - val_loss: 7.9998e-04 - val_accuracy: 0.0042\n",
      "Epoch 81/100\n",
      "958/958 [==============================] - 1s 533us/step - loss: 0.0011 - accuracy: 0.0010 - val_loss: 7.4308e-04 - val_accuracy: 0.0042\n",
      "Epoch 82/100\n",
      "958/958 [==============================] - 1s 556us/step - loss: 0.0011 - accuracy: 0.0010 - val_loss: 7.4189e-04 - val_accuracy: 0.0042\n",
      "Epoch 83/100\n",
      "958/958 [==============================] - 1s 559us/step - loss: 8.2954e-04 - accuracy: 0.0010 - val_loss: 5.7679e-04 - val_accuracy: 0.0042\n",
      "Epoch 84/100\n",
      "958/958 [==============================] - 1s 539us/step - loss: 0.0010 - accuracy: 0.0010 - val_loss: 5.8605e-04 - val_accuracy: 0.0042\n",
      "Epoch 85/100\n",
      "958/958 [==============================] - 1s 545us/step - loss: 0.0011 - accuracy: 0.0010 - val_loss: 8.3318e-04 - val_accuracy: 0.0042\n",
      "Epoch 86/100\n",
      "958/958 [==============================] - 1s 550us/step - loss: 9.5242e-04 - accuracy: 0.0010 - val_loss: 6.0983e-04 - val_accuracy: 0.0042\n",
      "Epoch 87/100\n",
      "958/958 [==============================] - 1s 540us/step - loss: 8.7948e-04 - accuracy: 0.0010 - val_loss: 8.2025e-04 - val_accuracy: 0.0042\n",
      "Epoch 88/100\n",
      "958/958 [==============================] - 1s 542us/step - loss: 8.1614e-04 - accuracy: 0.0010 - val_loss: 6.4692e-04 - val_accuracy: 0.0042\n",
      "Epoch 89/100\n",
      "958/958 [==============================] - 1s 537us/step - loss: 7.8970e-04 - accuracy: 0.0010 - val_loss: 6.6999e-04 - val_accuracy: 0.0042\n",
      "Epoch 90/100\n",
      "958/958 [==============================] - 1s 557us/step - loss: 8.5193e-04 - accuracy: 0.0010 - val_loss: 5.4412e-04 - val_accuracy: 0.0042\n",
      "Epoch 91/100\n",
      "958/958 [==============================] - 1s 556us/step - loss: 0.0011 - accuracy: 0.0010 - val_loss: 5.3814e-04 - val_accuracy: 0.0042\n",
      "Epoch 92/100\n",
      "958/958 [==============================] - 1s 543us/step - loss: 8.8017e-04 - accuracy: 0.0010 - val_loss: 7.5568e-04 - val_accuracy: 0.0042\n",
      "Epoch 93/100\n",
      "958/958 [==============================] - 1s 561us/step - loss: 8.1772e-04 - accuracy: 0.0010 - val_loss: 5.6173e-04 - val_accuracy: 0.0042\n",
      "Epoch 94/100\n",
      "958/958 [==============================] - 1s 548us/step - loss: 9.3980e-04 - accuracy: 0.0010 - val_loss: 5.6433e-04 - val_accuracy: 0.0042\n",
      "Epoch 95/100\n",
      "958/958 [==============================] - 1s 555us/step - loss: 8.7619e-04 - accuracy: 0.0010 - val_loss: 9.2207e-04 - val_accuracy: 0.0042\n",
      "Epoch 96/100\n",
      "958/958 [==============================] - 1s 539us/step - loss: 9.7041e-04 - accuracy: 0.0010 - val_loss: 9.3320e-04 - val_accuracy: 0.0042\n",
      "Epoch 97/100\n",
      "958/958 [==============================] - 1s 535us/step - loss: 8.8531e-04 - accuracy: 0.0010 - val_loss: 5.2609e-04 - val_accuracy: 0.0042\n",
      "Epoch 98/100\n",
      "958/958 [==============================] - 1s 540us/step - loss: 8.2874e-04 - accuracy: 0.0010 - val_loss: 6.0361e-04 - val_accuracy: 0.0042\n",
      "Epoch 99/100\n",
      "958/958 [==============================] - 1s 554us/step - loss: 8.3293e-04 - accuracy: 0.0010 - val_loss: 5.4957e-04 - val_accuracy: 0.0042\n",
      "Epoch 100/100\n",
      "958/958 [==============================] - 1s 565us/step - loss: 7.9132e-04 - accuracy: 0.0010 - val_loss: 7.2688e-04 - val_accuracy: 0.0042\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f15bb891f90>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the RNN to the Training set\n",
    "regressor.fit(X_train, y_train, epochs = 100, batch_size = 32, validation_split = 0.20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 50)                10400     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 10,451\n",
      "Trainable params: 10,451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "regressor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the real stock price of 2017\n",
    "dataset_test = pd.read_csv('Google_Stock_Price_Test.csv')\n",
    "real_stock_price = dataset_test.iloc[:, 1:2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the predicted stock price of 2017\n",
    "dataset_total = pd.concat((dataset_train['Open'], dataset_test['Open']), axis = 0)\n",
    "inputs = dataset_total[len(dataset_total) - len(dataset_test) - 60:].values\n",
    "inputs = inputs.reshape(-1,1)\n",
    "inputs = sc.transform(inputs)\n",
    "X_test = []\n",
    "for i in range(60, 80):\n",
    "    X_test.append(inputs[i-60:i, 0])\n",
    "X_test = np.array(X_test)\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "predicted_stock_price = regressor.predict(X_test)\n",
    "predicted_stock_price = sc.inverse_transform(predicted_stock_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualising the results\n",
    "plt.plot(real_stock_price, color = 'red', label = 'Real Google Stock Price')\n",
    "plt.plot(predicted_stock_price, color = 'blue', label = 'Predicted Google Stock Price')\n",
    "plt.title('Google Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Google Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
